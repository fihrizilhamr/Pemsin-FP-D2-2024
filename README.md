# Pemsin-FP-D2-2024
# Diabetes Prediction using Machine Learning

## Pendahuluan

Repository ini dibentuk untuk menyelesaikan tugas akhir Pembelajaran Mesin.

Anggota Kelompok D07:
| Nama | NRP |
| :---: | :---: |
| Akbar Putra Asenti Priyanto | 5025211004 |
| Arkana Bilal Imani | 5025211034 |
| Abdullah Yasykur Bifadhlil M. | 5025211035 |
| Fihriz Ilham Rabbany | 5025211040 |

```python
# -*- coding: utf-8 -*-
"""Pemsin-FP-D2-2024

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qxJdjxngn1jowWV6PwDGU_6qFJ9VhfmT

# Import Library & Dataset
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
warnings.filterwarnings("ignore")

from google.colab import userdata
import os

os.environ["KAGGLE_KEY"] = userdata.get('KAGGLE_KEY')
os.environ["KAGGLE_USERNAME"] = userdata.get('KAGGLE_USERNAME')

!kaggle datasets download -d iammustafatz/diabetes-prediction-dataset
!unzip "/content/diabetes-prediction-dataset.zip" -d "/content/diabetes-prediction-dataset"

df = pd.read_csv('/content/diabetes-prediction-dataset/diabetes_prediction_dataset.csv')
df.head()

def build_svc(X_train, y_train):
    model = SVC()
    return model

def build_logistic_regression(X_train, y_train):
    model = LogisticRegression()
    return model

def build_neural_network(X_train, y_train):
    model = Sequential()
    model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))
    model.add(Dense(8, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    model.fit(X_train, y_train, epochs=50, batch_size=10, validation_split=0.2, verbose=1)
    return model

def build_random_forest(X_train, y_train):
    model = RandomForestClassifier()
    return model

def evaluation(model, X_test, y_test):
    if hasattr(model, 'predict_proba'):
        y_pred_prob = model.predict_proba(X_test)[:, 1]
        y_pred = (y_pred_prob > 0.5).astype(int)
    else:
        y_pred = (model.predict(X_test) > 0.5).astype(int)

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    print("Accuracy:", accuracy)
    print("Precision:", precision)
    print("Recall:", recall)
    print("F1-score:", f1)
    print("\nClassification Report:\n", classification_report(y_test, y_pred))

    # Confusion Matrix
    conf_matrix = confusion_matrix(y_test, y_pred)
    sns.heatmap(conf_matrix, annot=True, fmt="d")
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

"""Drop atribut Unnamed:0 karena merupakan sebuah user id yang bersifat unique dan tidak menjadi parameter yang digunakan untuk prediksi"""

df.head()

"""# Missing data"""

df.isnull().sum()

df.info()

"""# Preprocessing"""

df = df.drop_duplicates()

df.groupby('diabetes').count()

df.groupby('gender').count()

df.groupby('smoking_history').count()

df.gender.replace({'Female': 1, 'Male': 0, 'Other':2}, inplace=True)
df.smoking_history.replace({'never': 0, 'ever': 1, 'former':1, 'not current':1, 'current':2, 'No Info':2}, inplace=True)
df

for column in df.columns:
    if df[column].dtype in ['int64', 'float64']:
        plt.figure()
        df[column].plot(kind='hist', bins=20, title=column)
        plt.gca().spines[['top', 'right']].set_visible(False)
        plt.show()
    else:
        print(f"Skipping column {column} because it contains non-numeric data.")

corr = df.corr()
plt.figure(figsize=(16, 16))
sns.heatmap(corr, annot=True, fmt=".1%")

plt.show()

new_df = df.copy()
df

"""# Standarisasi"""

scaler = StandardScaler()
X = df.drop('diabetes', axis=1)
y = df['diabetes']
X_scaled = scaler.fit_transform(X)

"""# Split data to data test and train"""

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.20)
X = df.drop('diabetes', axis=1)
y = df['diabetes']

"""# Build Model Neural Network and Evaluation"""

svc_model = build_svc(X_train, y_train)
logistic_model = build_logistic_regression(X_train, y_train)
nn_model = build_neural_network(X_train, y_train)
rf_model = build_random_forest(X_train, y_train)
evaluation(svc_model, X_test, y_test)
evaluation(logistic_model, X_test, y_test)
evaluation(nn_model, X_test, y_test)
evaluation(rf_model, X_test, y_test)
```
